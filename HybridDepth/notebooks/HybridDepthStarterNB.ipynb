{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides an easy to use interface for the depth estimation model \"HybriDepth\".\n",
    "\n",
    "It accompanies our paper : <a href=\"https://arxiv.org/pdf/2407.18443\">Hybrid Depth: Robust Depth Fusion By Leveraging Depth from Focus and Single-Image Priors</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bguQDH-XsWwF"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sD3ONqi6tN1U",
    "outputId": "2bb9a4e1-99fc-4ace-a5ee-53b7108e2b95"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/cake-lab/HybridDepth.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bsAH3fQfoWxn",
    "outputId": "aad9afc3-e112-442d-aa2d-59b12a80d19b"
   },
   "outputs": [],
   "source": [
    "!pip install kornia==0.6.7\n",
    "!pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ./HybridDepth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "id": "3pSJVuVuZqHk",
    "outputId": "3a4b8403-f47d-4457-9d2d-4b8920e2c048"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.io import prepare_input_image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAV1Q0TSsmcY"
   },
   "source": [
    "# Load model\n",
    "\n",
    "Select one of our pre-trained HybridDepth models, each fine-tuned on different datasets and configurations. Specify the desired model configuration and initialize it with `pretrained=True` to load the pre-trained weights.\n",
    "\n",
    "Available Pre-trained Models:\n",
    "\n",
    "* `\"HybridDepth_NYU5\"`: Pre-trained on the NYU Depth V2 dataset using a 5-focal stack input, with both the DFF branch and refinement layer trained.\n",
    "* `\"HybridDepth_NYU10\"`: Pre-trained on the NYU Depth V2 dataset using a 10-focal stack input, with both the DFF branch and refinement layer trained.\n",
    "* `\"HybridDepth_DDFF5\"`: Pre-trained on the DDFF dataset using a 5-focal stack input.\n",
    "* `\"HybridDepth_NYU_PretrainedDFV5\"`: Pre-trained only on the refinement layer with NYU Depth V2 dataset using a 5-focal stack, following pre-training with DFV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOyTHypMZ0EW"
   },
   "outputs": [],
   "source": [
    "# Choose a model by setting model_name to one of the options above.\n",
    "# Example: Load the HybridDepth model pre-trained on NYU with DFV pre-training (5-focal stack).\n",
    "model_name = 'HybridDepth_NYU_PretrainedDFV5'\n",
    "model = torch.hub.load('cake-lab/HybridDepth', model_name, pretrained=True)\n",
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWVSxKSTssf5"
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-a80EgkIZ7vS"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/cake-lab/HybridDepth/releases/download/v2.0/examples.zip\n",
    "\n",
    "!unzip examples.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWkcfCmLs5MY"
   },
   "source": [
    "### Select example 00 or 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uI6CJsIErprt"
   },
   "outputs": [],
   "source": [
    "# focal_stack, rgb_img, focus_dist = prepare_input_image('./example00')\n",
    "focal_stack, rgb_img, focus_dist = prepare_input_image('./example01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dUg_Smz-s8tN"
   },
   "source": [
    "### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5zXgE8vHr58Z"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(rgb_img, focal_stack, focus_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JoNQxJ6ls_rL"
   },
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ARd4dqm5sABg"
   },
   "outputs": [],
   "source": [
    "metric_depth = out[0].squeeze().cpu().numpy()\n",
    "rgb_img = rgb_img.squeeze().cpu().numpy().transpose(1, 2, 0)\n",
    "rgb_img = (rgb_img * 255).astype(np.uint8)\n",
    "\n",
    "# visualize the results RGB + depth\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(rgb_img)\n",
    "plt.title('RGB Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(metric_depth, cmap='plasma')\n",
    "plt.title('Depth Map')\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('Depth (meters)')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GUldvwZ4sIL9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
