{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def save_vis_from_lists(rgb_list, ours_list, dfv_list, depth_anything_list, gt_depth_list, dir_name='default'):\n",
    "    \"\"\"\n",
    "    Displays multiple sets of images in rows: RGB, Ours (Predictions), DFV Depth, Depth Anything, and GT Depth.\n",
    "    Handles input images of shape (1, 1, h, w) or (3, h, w) for RGB. Calculates MIN_DISP and MAX_DISP based on GT depths\n",
    "    separately for each sample.\n",
    "    \n",
    "    Parameters:\n",
    "    - rgb_list: List of RGB images (shape (3, h, w) or (1, 1, h, w)).\n",
    "    - ours_list: List of model prediction images (shape (1, 1, h, w)).\n",
    "    - dfv_list: List of DFV depth images (shape (1, 1, h, w)).\n",
    "    - depth_anything_list: List of Depth Anything depth images (shape (1, 1, h, w)).\n",
    "    - gt_depth_list: List of ground truth (GT) depth images (shape (1, 1, h, w)).\n",
    "    - dir_name: Directory name to save the image visualization.\n",
    "    \"\"\"\n",
    "    # pred viz\n",
    "    outdir = '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs'\n",
    "    img_save_pth = os.path.join(os.path.abspath(outdir), dir_name)\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    if not os.path.isdir(img_save_pth):\n",
    "        os.makedirs(img_save_pth)\n",
    "    \n",
    "    num_images = len(rgb_list)\n",
    "\n",
    "    fig, axs = plt.subplots(num_images, 5, figsize=(9, 4))  # Adjust size based on number of images\n",
    "    plt.subplots_adjust(wspace=0.00, hspace=0.04)  # Less vertical space between rows\n",
    "    \n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    plt.rcParams['font.size'] = 11\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # Extract the (h, w) shape from (1, 1, h, w) or handle (3, h, w) for RGB\n",
    "        rgb_img = rgb_list[i].squeeze()\n",
    "        if rgb_img.shape[0] == 3:  # Handle (3, h, w) case for RGB images\n",
    "            rgb_img = rgb_img.transpose(1, 2, 0)  # Convert (3, h, w) -> (h, w, 3)\n",
    "            \n",
    "            # Normalize RGB data to [0, 1] if it's float and outside this range\n",
    "            if rgb_img.dtype == np.float32 or rgb_img.dtype == np.float64:\n",
    "                rgb_img = np.clip(rgb_img, 0.0, 1.0)\n",
    "            elif rgb_img.dtype == np.int32 or rgb_img.dtype == np.int64:\n",
    "                rgb_img = np.clip(rgb_img, 0, 255)  # Clip integer values to the range [0, 255]\n",
    "\n",
    "        ours_img = ours_list[i].squeeze()  \n",
    "        dfv_img = dfv_list[i].squeeze()\n",
    "        depth_any_img = depth_anything_list[i].squeeze()\n",
    "        gt_depth_img = gt_depth_list[i].squeeze()\n",
    "\n",
    "        # Calculate MIN_DISP and MAX_DISP for this specific sample based on GT\n",
    "        MIN_DISP = gt_depth_img.min()\n",
    "        MAX_DISP = gt_depth_img.max()\n",
    "\n",
    "        # Rotate last images by 180 degrees\n",
    "        if i + 1 == num_images:\n",
    "            ours_img = np.rot90(ours_img, 2)\n",
    "            dfv_img = np.rot90(dfv_img, 2)\n",
    "            depth_any_img = np.rot90(depth_any_img, 2)\n",
    "            gt_depth_img = np.rot90(gt_depth_img, 2)\n",
    "            rgb_img = np.rot90(rgb_img, 2)\n",
    "        \n",
    "        # Plot RGB image\n",
    "        axs[i, 0].imshow(rgb_img)  # Removed cmap for RGB since it's now in (h, w, 3)\n",
    "        axs[i, 0].axis('off')\n",
    "\n",
    "        # Plot Ours (Predictions)\n",
    "        axs[i, 1].imshow(ours_img, cmap='plasma', vmin=MIN_DISP, vmax=MAX_DISP)\n",
    "        axs[i, 1].axis('off')\n",
    "\n",
    "        # Plot DFV Depth\n",
    "        axs[i, 2].imshow(dfv_img, cmap='plasma', vmin=MIN_DISP, vmax=MAX_DISP)\n",
    "        axs[i, 2].axis('off')\n",
    "\n",
    "        # Plot Depth Anything\n",
    "        axs[i, 3].imshow(depth_any_img, cmap='plasma', vmin=MIN_DISP, vmax=MAX_DISP)\n",
    "        axs[i, 3].axis('off')\n",
    "\n",
    "        # Plot Ground Truth (GT) Depth\n",
    "        axs[i, 4].imshow(gt_depth_img, cmap='plasma')\n",
    "        axs[i, 4].axis('off')\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(os.path.join(img_save_pth, f'{dir_name}_pred_viz_diff.png'), bbox_inches='tight', pad_inches=0, dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load depth anything\n",
    "depthAnything_260 = np.load('/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/ARKitSceneVis/depthAnything_data/learned_pred_260.npy')\n",
    "depthAnything_381= np.load('/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/ARKitSceneVis/depthAnything_data/learned_pred_381.npy')\n",
    "depthAnything_1700 = np.load('/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/ARKitSceneVis/depthAnything_data/learned_pred_1700.npy')\n",
    "\n",
    "depthAnything = [depthAnything_260, depthAnything_381, depthAnything_1700]\n",
    "\n",
    "ours_260 = np.load('/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/ARKitSceneVis/ours_data/260_depth.npy')\n",
    "ours_381 = np.load('/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/ARKitSceneVis/ours_data/381_depth.npy')\n",
    "ours_1700 = np.load('/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/ARKitSceneVis/ours_data/1700_depth.npy')\n",
    "\n",
    "ours = [ours_260,ours_381, ours_1700]\n",
    "\n",
    "dfv_260 = np.load('/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/ARKitSceneVis/dfv_data/260_DFV_prd.npy')\n",
    "dfv_381 = np.load('/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/ARKitSceneVis/dfv_data/381_DFV_prd.npy')\n",
    "dfv_1700 = np.load('/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/ARKitSceneVis/dfv_data/1700_DFV_prd.npy')\n",
    "\n",
    "\n",
    "dfs = [dfv_260, dfv_381, dfv_1700]\n",
    "\n",
    "gt_260 = np.load('/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/ARKitSceneVis/gt_data/260_gt.npy')\n",
    "gt_381 = np.load('/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/ARKitSceneVis/gt_data/381_gt.npy')\n",
    "gt_1700 = np.load('/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/ARKitSceneVis/gt_data/1700_gt.npy')\n",
    "\n",
    "gts = [gt_260, gt_381, gt_1700]\n",
    "\n",
    "rgb_260 = np.load('/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/ARKitSceneVis/rgb_data/260_rgb.npy')\n",
    "rgb_381 = np.load('/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/ARKitSceneVis/rgb_data/381_rgb.npy')\n",
    "rgb_1700 = np.load('/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/ARKitSceneVis/rgb_data/1700_rgb.npy')\n",
    "\n",
    "\n",
    "rgbs = [rgb_260, rgb_381, rgb_1700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_vis_from_lists(rgbs, ours, dfs, depthAnything, gts, 'ARKitSceneVis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
