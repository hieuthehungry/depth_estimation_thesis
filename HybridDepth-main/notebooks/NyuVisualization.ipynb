{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def save_vis_from_lists(rgb_list, ours_list, depth_anything_list, gt_depth_list, dir_name='default'):\n",
    "    \"\"\"\n",
    "    Displays multiple sets of images in rows: RGB, Ours (Predictions), DFV Depth, Depth Anything, and GT Depth.\n",
    "    Handles input images of shape (1, 1, h, w) or (3, h, w) for RGB. Calculates MIN_DISP and MAX_DISP based on GT depths\n",
    "    separately for each sample.\n",
    "    \n",
    "    Parameters:\n",
    "    - rgb_list: List of RGB images (shape (3, h, w) or (1, 1, h, w)).\n",
    "    - ours_list: List of model prediction images (shape (1, 1, h, w)).\n",
    "    - dfv_list: List of DFV depth images (shape (1, 1, h, w)).\n",
    "    - depth_anything_list: List of Depth Anything depth images (shape (1, 1, h, w)).\n",
    "    - gt_depth_list: List of ground truth (GT) depth images (shape (1, 1, h, w)).\n",
    "    - dir_name: Directory name to save the image visualization.\n",
    "    \"\"\"\n",
    "    # pred viz\n",
    "    outdir = '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs'\n",
    "    img_save_pth = os.path.join(os.path.abspath(outdir), dir_name)\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    if not os.path.isdir(img_save_pth):\n",
    "        os.makedirs(img_save_pth)\n",
    "    \n",
    "    num_images = len(rgb_list)\n",
    "\n",
    "    fig, axs = plt.subplots(num_images, 4, figsize=(5,7))  # Adjust size based on number of images\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.0)  # Less vertical space between rows\n",
    "    \n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    plt.rcParams['font.size'] = 11\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # Extract the (h, w) shape from (1, 1, h, w) or handle (3, h, w) for RGB\n",
    "        rgb_img = rgb_list[i].squeeze()\n",
    "        if rgb_img.shape[0] == 3:  # Handle (3, h, w) case for RGB images\n",
    "            rgb_img = rgb_img.transpose(1, 2, 0)  # Convert (3, h, w) -> (h, w, 3)\n",
    "            \n",
    "            # Normalize RGB data to [0, 1] if it's float and outside this range\n",
    "            if rgb_img.dtype == np.float32 or rgb_img.dtype == np.float64:\n",
    "                rgb_img = np.clip(rgb_img, 0.0, 1.0)\n",
    "            elif rgb_img.dtype == np.int32 or rgb_img.dtype == np.int64:\n",
    "                rgb_img = np.clip(rgb_img, 0, 255)  # Clip integer values to the range [0, 255]\n",
    "\n",
    "        ours_img = ours_list[i].squeeze()  \n",
    "        depth_any_img = depth_anything_list[i].squeeze()\n",
    "        gt_depth_img = gt_depth_list[i].squeeze()\n",
    "\n",
    "        # Calculate MIN_DISP and MAX_DISP for this specific sample based on GT\n",
    "        MIN_DISP = gt_depth_img.min()\n",
    "        MAX_DISP = gt_depth_img.max()\n",
    "\n",
    "        \n",
    "        # Plot RGB image\n",
    "        axs[i, 0].imshow(rgb_img)  # Removed cmap for RGB since it's now in (h, w, 3)\n",
    "        axs[i, 0].axis('off')\n",
    "\n",
    "        # Plot Ours (Predictions)\n",
    "        axs[i, 1].imshow(ours_img, cmap='plasma', vmin=MIN_DISP, vmax=MAX_DISP)\n",
    "        axs[i, 1].axis('off')\n",
    "\n",
    "        # Plot Depth Anything\n",
    "        axs[i, 2].imshow(depth_any_img, cmap='plasma', vmin=MIN_DISP, vmax=MAX_DISP)\n",
    "        axs[i, 2].axis('off')\n",
    "\n",
    "        # Plot Ground Truth (GT) Depth\n",
    "        axs[i, 3].imshow(gt_depth_img, cmap='plasma')\n",
    "        axs[i, 3].axis('off')\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(os.path.join(img_save_pth, f'{dir_name}_pred_viz_diff.png'), bbox_inches='tight', pad_inches=0, dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_depth_list_pth = [\n",
    "    # '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/gt_data/0_gt.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/gt_data/10_gt.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/gt_data/20_gt.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/gt_data/30_gt.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/gt_data/100_gt.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/gt_data/110_gt.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/gt_data/160_gt.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/gt_data/180_gt.npy',\n",
    "    # '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/gt_data/380_gt.npy',\n",
    "    # '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/gt_data/400_gt.npy'\n",
    "]\n",
    "\n",
    "gt_depth = [np.load(pth) for pth in gt_depth_list_pth]\n",
    "\n",
    "\n",
    "rgb_list_pth = [\n",
    "    # '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/rgb_data/0_rgb.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/rgb_data/10_rgb.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/rgb_data/20_rgb.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/rgb_data/30_rgb.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/rgb_data/100_rgb.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/rgb_data/110_rgb.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/rgb_data/160_rgb.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/rgb_data/180_rgb.npy',\n",
    "    # '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/rgb_data/380_rgb.npy',\n",
    "    # '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/rgb_data/400_rgb.npy'\n",
    "]\n",
    "\n",
    "rgb = [np.load(pth) for pth in rgb_list_pth]\n",
    "\n",
    "ours_list_pth = [\n",
    "    # '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/ours_data/0_depth.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/ours_data/10_depth.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/ours_data/20_depth.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/ours_data/30_depth.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/ours_data/100_depth.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/ours_data/110_depth.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/ours_data/160_depth.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/ours_data/180_depth.npy',\n",
    "    # '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/ours_data/380_depth.npy',\n",
    "    # '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/ours_data/400_depth.npy'\n",
    "]\n",
    "\n",
    "ours = [np.load(pth) for pth in ours_list_pth]\n",
    "\n",
    "depthanything_list_pth = [\n",
    "    # '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/depthanything_data/0_depthanything.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/depthanything_data/10_depthanything.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/depthanything_data/20_depthanything.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/depthanything_data/30_depthanything.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/depthanything_data/100_depthanything.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/depthanything_data/110_depthanything.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/depthanything_data/160_depthanything.npy',\n",
    "    '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/depthanything_data/180_depthanything.npy',\n",
    "    # '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/depthanything_data/380_depthanything.npy',\n",
    "    # '/home/ashkanganj/workspace/2023-HybridDepth-DepthProject/results/imgs/NyuVis/depthanything_data/400_depthanything.npy'\n",
    "]\n",
    "\n",
    "depthanything = [np.load(pth) for pth in depthanything_list_pth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_vis_from_lists(rgb, ours, depthanything, gt_depth, dir_name='NyuVis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
